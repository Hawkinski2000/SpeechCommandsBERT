# SpeechCommandsBERT
This project implements a transformer-based model for single-word speech classification using the Google Speech Commands dataset. Inspired by BERT and Whisper, the model processes log-mel spectrograms as inputs and classifies them into predefined speech commands. The model uses a modified version of [Andrej Karpathy's reproduction of GPT-2 (124M)](https://github.com/karpathy/build-nanogpt 'build-nanogpt').